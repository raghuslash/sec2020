{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "import sys\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import keract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to load data\n",
    "\n",
    "def data_loader(filepath):\n",
    "    data = h5py.File(filepath, 'r')\n",
    "    x_data = np.array(data['data'])\n",
    "    y_data = np.array(data['label'])\n",
    "    x_data = x_data.transpose((0,2,3,1))\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths to the model and data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/sunglasses_bd_net.h5'\n",
    "clean_data_path = 'data/clean_test_data.h5'\n",
    "pois_data_path = 'data/sunglasses_poisoned_data.h5'\n",
    "val_data_path = 'data/clean_validation_data.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data from the h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_model = keras.models.load_model(model_path)\n",
    "x_clean, y_clean = data_loader(clean_data_path)\n",
    "x_pois, y_pois = data_loader(pois_data_path)\n",
    "x_val, y_val = data_loader(val_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first create a data generator to carry out finding the trigger in batches. Let's say thta the badnet is infected to classify into label target label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = np.unique(y_clean).shape[0]\n",
    "target = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "generator = datagen.flow(x_clean, y_clean, batch_size=32) # We'll use a batch size of 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with a random mask and a random pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = bd_model.input_shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_init = np.random.random(bd_model.input_shape[1:]) * 255.0\n",
    "mask_init = np.random.random(bd_model.input_shape[1:3])\n",
    "mask_init = np.expand_dims(mask_init, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = pattern_init\n",
    "mask = mask_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tanh space\n",
    "mask_tanh = np.arctanh((mask - 0.5) * (2 - K.epsilon()))\n",
    "pattern_tanh = np.arctanh((pattern / 255.0 - 0.5) * (2 - K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import UpSampling2D, Cropping2D\n",
    "# prepare mask related tensors\n",
    "upsample_size = 1\n",
    "mask_tanh_tensor = K.variable(mask_tanh)\n",
    "mask_tensor_unrepeat = (K.tanh(mask_tanh_tensor) / (2 - K.epsilon()) + 0.5)\n",
    "mask_tensor_unexpand = K.repeat_elements(mask_tensor_unrepeat, rep=3, axis=2)\n",
    "mask_tensor = K.expand_dims(mask_tensor_unexpand, axis=0)\n",
    "upsample_layer = UpSampling2D(size=(upsample_size, upsample_size))\n",
    "mask_upsample_tensor_uncrop = upsample_layer(mask_tensor)\n",
    "uncrop_shape = K.int_shape(mask_upsample_tensor_uncrop)[1:]\n",
    "cropping_layer = Cropping2D(cropping=((0, uncrop_shape[0] - input_shape[0]), (0, uncrop_shape[1] - input_shape[1])))\n",
    "mask_upsample_tensor = cropping_layer(mask_upsample_tensor_uncrop)\n",
    "reverse_mask_tensor = (K.ones_like(mask_upsample_tensor) - mask_upsample_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare pattern related tensors\n",
    "pattern_tanh_tensor = K.variable(pattern_tanh)\n",
    "pattern_raw_tensor = ((K.tanh(pattern_tanh_tensor) / (2 - K.epsilon()) + 0.5) * 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adverserial input tensor\n",
    "input_tensor = K.placeholder(bd_model.input_shape)\n",
    "input_raw_tensor = input_tensor\n",
    "X_adv_raw_tensor = (reverse_mask_tensor * input_raw_tensor * 255.0 + mask_upsample_tensor * pattern_raw_tensor)\n",
    "X_adv_tensor = X_adv_raw_tensor / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor = bd_model(X_adv_tensor)\n",
    "y_true_tensor = K.placeholder(bd_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import categorical_crossentropy\n",
    "from keras.metrics import categorical_accuracy\n",
    "\n",
    "loss_ce = categorical_crossentropy(output_tensor, y_true_tensor)\n",
    "loss_acc = categorical_accuracy(output_tensor, y_true_tensor)\n",
    "loss_reg = K.constant(0)\n",
    "loss = loss_ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.1, beta_1=0.5, beta_2=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = opt.get_updates(loss, [pattern_tanh_tensor, mask_tanh_tensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = K.function([input_tensor, y_true_tensor], [loss_ce, loss_reg, loss, loss_acc], updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_succ_threshold = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_opt(opt):\n",
    "    K.set_value(opt.iterations, 0)\n",
    "    for w in opt.weights:\n",
    "        K.set_value(w, np.zeros(K.int_shape(w)))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_state(mask_init, pattern_init, opt):\n",
    "    global mask_tanh_tensor, pattern_tanh_tensor\n",
    "    # setting mask and pattern\n",
    "    mask = np.array(mask_init)\n",
    "    pattern = np.array(pattern_init)\n",
    "    mask = np.clip(mask, 0, 1)\n",
    "    pattern = np.clip(pattern, 0, 255)\n",
    "\n",
    "    # convert to tanh space\n",
    "    mask_tanh = np.arctanh((mask - 0.5) * (2 - K.epsilon()))\n",
    "    pattern_tanh = np.arctanh((pattern / 255.0 - 0.5) * (2 - K.epsilon()))\n",
    "    print('mask_tanh', np.min(mask_tanh), np.max(mask_tanh))\n",
    "    print('pattern_tanh', np.min(pattern_tanh), np.max(pattern_tanh))\n",
    "\n",
    "    K.set_value(mask_tanh_tensor, mask_tanh)\n",
    "    K.set_value(pattern_tanh_tensor, pattern_tanh)\n",
    "    # resetting optimizer states\n",
    "    reset_opt(opt)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(1000):\n",
    "    mini_batch = int(np.ceil(12830 / 32))\n",
    "    reset_state(mask_init, pattern_init, opt)\n",
    "    # record loss for all mini-batches\n",
    "    # best optimization results\n",
    "    mask_best = None\n",
    "    mask_upsample_best = None\n",
    "    pattern_best = None\n",
    "    reg_best = float('inf')\n",
    "    loss_ce_list = []\n",
    "    loss_reg_list = []\n",
    "    loss_list = []\n",
    "    loss_acc_list = []\n",
    "    for idx in range(mini_batch):\n",
    "        X_batch, y_batch = generator.next()\n",
    "        Y_target = to_categorical([target] * X_batch.shape[0], num_labels)\n",
    "        (loss_ce_value, loss_reg_value, loss_value, loss_acc_value) = train([X_batch, Y_target])\n",
    "        loss_ce_list.extend(list(loss_ce_value.flatten()))\n",
    "        loss_reg_list.extend(list(loss_reg_value.flatten()))\n",
    "        loss_list.extend(list(loss_value.flatten()))\n",
    "        loss_acc_list.extend(list(loss_acc_value.flatten()))\n",
    "    avg_loss_ce = np.mean(loss_ce_list)\n",
    "    avg_loss_reg = np.mean(loss_reg_list)\n",
    "    avg_loss = np.mean(loss_list)\n",
    "    avg_loss_acc = np.mean(loss_acc_list)\n",
    "    \n",
    "    print('step: %3d, attack: %.3f, loss: %f, ce: %f, reg: %f, reg_best: %f' %\n",
    "                          (step, avg_loss_acc, avg_loss,\n",
    "                           avg_loss_ce, avg_loss_reg, reg_best))\n",
    "\n",
    "    if avg_loss_acc >= attack_succ_threshold and avg_loss_reg < reg_best:\n",
    "        mask_best = K.eval(mask_tensor)\n",
    "        mask_best = mask_best[0, ..., 0]\n",
    "        mask_upsample_best = K.eval(mask_upsample_tensor)\n",
    "        mask_upsample_best = mask_upsample_best[0, ..., 0]\n",
    "        pattern_best = K.eval(pattern_raw_tensor)\n",
    "        reg_best = avg_loss_reg\n",
    "        \n",
    "    if mask_best is None:\n",
    "        mask_best = K.eval(mask_tensor)\n",
    "        mask_best = mask_best[0, ..., 0]\n",
    "        mask_upsample_best = K.eval(mask_upsample_tensor)\n",
    "        mask_upsample_best = mask_upsample_best[0, ..., 0]\n",
    "        pattern_best = K.eval(pattern_raw_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
